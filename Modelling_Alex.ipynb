{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abohane/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned datasets with weather data\n",
    "\n",
    "train_data = pd.read_csv('df_train.csv')\n",
    "test_data = pd.read_csv('df_test.csv')\n",
    "\n",
    "train_data.set_index('date', inplace=True)\n",
    "test_data.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define target variables and features\n",
    "target_variables = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "# Features available in both train and test sets\n",
    "common_features = ['temperature', 'humidite', 'vent_moyen', 'vent_direction', 'pluie_1h']\n",
    "\n",
    "# Time features (assuming they are derived from 'date' and can be computed for the test set)\n",
    "time_features = ['hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "# Lag features and rolling statistics (not available in test set, we'll handle them separately)\n",
    "lag_features = [col for col in train_data.columns if 'lag' in col]\n",
    "rolling_features = [col for col in train_data.columns if 'rolling' in col]\n",
    "\n",
    "# Interaction features (we can recompute them)\n",
    "interaction_features = ['NO2_CO_interaction', 'PM10_PM25_interaction']\n",
    "\n",
    "# All features for training\n",
    "feature_columns = common_features + time_features + lag_features + rolling_features + interaction_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the data for modeling\n",
    "\n",
    "# Ensure the date index is in datetime format\n",
    "train_data.index = pd.to_datetime(train_data.index)\n",
    "test_data.index = pd.to_datetime(test_data.index)\n",
    "\n",
    "# Generate time features for test_data\n",
    "test_data['hour'] = test_data.index.hour\n",
    "test_data['day_of_week'] = test_data.index.dayofweek\n",
    "test_data['month'] = test_data.index.month\n",
    "\n",
    "# Create cyclic features\n",
    "test_data['hour_sin'] = np.sin(2 * np.pi * test_data['hour'] / 24)\n",
    "test_data['hour_cos'] = np.cos(2 * np.pi * test_data['hour'] / 24)\n",
    "test_data['day_of_week_sin'] = np.sin(2 * np.pi * test_data['day_of_week'] / 7)\n",
    "test_data['day_of_week_cos'] = np.cos(2 * np.pi * test_data['day_of_week'] / 7)\n",
    "test_data['month_sin'] = np.sin(2 * np.pi * test_data['month'] / 12)\n",
    "test_data['month_cos'] = np.cos(2 * np.pi * test_data['month'] / 12)\n",
    "\n",
    "# Drop intermediate columns\n",
    "test_data.drop(['hour', 'day_of_week', 'month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the final features for modeling\n",
    "final_features = common_features + time_features + interaction_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in train_data\n",
    "train_data = train_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Implement time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "  Training model for valeur_NO2...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 16.200001\n",
      "  Training model for valeur_CO...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.175000\n",
      "  Training model for valeur_O3...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 54.799999\n",
      "  Training model for valeur_PM10...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 17.600000\n",
      "  Training model for valeur_PM25...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 8.700000\n",
      "Training fold 2...\n",
      "  Training model for valeur_NO2...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1647\n",
      "[LightGBM] [Info] Number of data points in the train set: 13611, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 18.700001\n",
      "  Training model for valeur_CO...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1647\n",
      "[LightGBM] [Info] Number of data points in the train set: 13611, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.244000\n",
      "  Training model for valeur_O3...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1647\n",
      "[LightGBM] [Info] Number of data points in the train set: 13611, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 52.000000\n",
      "  Training model for valeur_PM10...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1647\n",
      "[LightGBM] [Info] Number of data points in the train set: 13611, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 17.100000\n",
      "  Training model for valeur_PM25...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1647\n",
      "[LightGBM] [Info] Number of data points in the train set: 13611, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 9.100000\n",
      "Training fold 3...\n",
      "  Training model for valeur_NO2...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1658\n",
      "[LightGBM] [Info] Number of data points in the train set: 20414, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 20.299999\n",
      "  Training model for valeur_CO...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1658\n",
      "[LightGBM] [Info] Number of data points in the train set: 20414, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.233000\n",
      "  Training model for valeur_O3...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1658\n",
      "[LightGBM] [Info] Number of data points in the train set: 20414, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 50.000000\n",
      "  Training model for valeur_PM10...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1658\n",
      "[LightGBM] [Info] Number of data points in the train set: 20414, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 17.299999\n",
      "  Training model for valeur_PM25...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1658\n",
      "[LightGBM] [Info] Number of data points in the train set: 20414, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 9.500000\n",
      "Training fold 4...\n",
      "  Training model for valeur_NO2...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1662\n",
      "[LightGBM] [Info] Number of data points in the train set: 27217, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 19.799999\n",
      "  Training model for valeur_CO...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1662\n",
      "[LightGBM] [Info] Number of data points in the train set: 27217, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.218000\n",
      "  Training model for valeur_O3...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1662\n",
      "[LightGBM] [Info] Number of data points in the train set: 27217, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 49.099998\n",
      "  Training model for valeur_PM10...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1662\n",
      "[LightGBM] [Info] Number of data points in the train set: 27217, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 17.200001\n",
      "  Training model for valeur_PM25...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1662\n",
      "[LightGBM] [Info] Number of data points in the train set: 27217, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 9.300000\n",
      "Training fold 5...\n",
      "  Training model for valeur_NO2...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 34020, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 18.799999\n",
      "  Training model for valeur_CO...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 34020, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.206000\n",
      "  Training model for valeur_O3...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 34020, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 50.599998\n",
      "  Training model for valeur_PM10...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 34020, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 16.700001\n",
      "  Training model for valeur_PM25...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 34020, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 9.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 5 (Adjusted): Train separate models for each pollutant\n",
    "\n",
    "# Prepare the training data\n",
    "X = train_data[final_features]\n",
    "\n",
    "# Initialize a dictionary to store models for each pollutant\n",
    "models = {}\n",
    "mae_scores = []\n",
    "\n",
    "# Iterate through each split\n",
    "for fold, (train_index, val_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "\n",
    "    fold_mae = {}\n",
    "    fold_models = {}\n",
    "\n",
    "    for pollutant in target_variables:\n",
    "        print(f\"  Training model for {pollutant}...\")\n",
    "        y_train = train_data.iloc[train_index][pollutant]\n",
    "        y_val = train_data.iloc[val_index][pollutant]\n",
    "\n",
    "        # Initialize the LightGBM regressor\n",
    "        lgbm_reg = lgb.LGBMRegressor(\n",
    "            objective='regression_l1',\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        lgbm_reg.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='mae',\n",
    "        )\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = lgbm_reg.predict(X_val)\n",
    "\n",
    "        # Compute MAE\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        fold_mae[pollutant] = mae\n",
    "        fold_models[pollutant] = lgbm_reg\n",
    "\n",
    "    mae_scores.append(fold_mae)\n",
    "\n",
    "    # After last fold, save the models\n",
    "    if fold == tscv.get_n_splits() - 1:\n",
    "        models = fold_models  # Use models from the last fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scores across folds:\n",
      "   valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25\n",
      "0    7.340618   0.082819  10.965511     2.715187     1.513925\n",
      "1    5.607390   0.053429   8.098471     1.808041     1.089944\n",
      "2    4.417616   0.053574   8.792999     1.705617     0.899640\n",
      "3    2.657229   0.029609   7.674783     1.644027     0.902760\n",
      "4    2.407709   0.026069   7.523596     1.208033     0.672109\n",
      "\n",
      "Average MAE:\n",
      "valeur_NO2     4.486112\n",
      "valeur_CO      0.049100\n",
      "valeur_O3      8.611072\n",
      "valeur_PM10    1.816181\n",
      "valeur_PM25    1.015676\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze MAE scores\n",
    "mae_df = pd.DataFrame(mae_scores)\n",
    "print(\"MAE scores across folds:\")\n",
    "print(mae_df)\n",
    "print(\"\\nAverage MAE:\")\n",
    "print(mae_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Implement recursive forecasting for the test set\n",
    "\n",
    "# Initialize test_data with necessary features\n",
    "test_data_pred = test_data.copy()\n",
    "test_data_pred[interaction_features] = 0  # Initialize interaction features\n",
    "\n",
    "# We need to generate lag features and rolling statistics recursively\n",
    "# We'll start by getting the last known values from the training data\n",
    "\n",
    "# Get the last known values for lag features\n",
    "last_known_values = train_data.iloc[-168:]  # Get last 168 hours for lag168\n",
    "\n",
    "# Initialize an empty DataFrame to store predictions\n",
    "test_predictions = pd.DataFrame(index=test_data_pred.index, columns=target_variables)\n",
    "\n",
    "# Iterate over each time step in the test set\n",
    "for i, timestamp in enumerate(test_data_pred.index):\n",
    "    # Prepare the input features\n",
    "    X_test = test_data_pred.loc[[timestamp], common_features + time_features + interaction_features]\n",
    "\n",
    "    # For the first few steps, we can use the last known lag values from the training set\n",
    "    if i == 0:\n",
    "        # Lag 1\n",
    "        for pollutant in target_variables:\n",
    "            lag1_value = train_data.iloc[-1][pollutant]\n",
    "            X_test[f'{pollutant}_lag1'] = lag1_value\n",
    "        # Lag 24\n",
    "        if len(train_data) >= 24:\n",
    "            for pollutant in target_variables:\n",
    "                lag24_value = train_data.iloc[-24][pollutant]\n",
    "                X_test[f'{pollutant}_lag24'] = lag24_value\n",
    "        else:\n",
    "            # Not enough data for lag24, use last known value\n",
    "            for pollutant in target_variables:\n",
    "                X_test[f'{pollutant}_lag24'] = train_data.iloc[-1][pollutant]\n",
    "        # Lag 168\n",
    "        if len(train_data) >= 168:\n",
    "            for pollutant in target_variables:\n",
    "                lag168_value = train_data.iloc[-168][pollutant]\n",
    "                X_test[f'{pollutant}_lag168'] = lag168_value\n",
    "        else:\n",
    "            # Not enough data for lag168, use last known value\n",
    "            for pollutant in target_variables:\n",
    "                X_test[f'{pollutant}_lag168'] = train_data.iloc[-1][pollutant]\n",
    "        # Rolling means and stds\n",
    "        for pollutant in target_variables:\n",
    "            rolling_mean24 = train_data[pollutant].rolling(window=24).mean().iloc[-1]\n",
    "            rolling_std24 = train_data[pollutant].rolling(window=24).std().iloc[-1]\n",
    "            rolling_mean168 = train_data[pollutant].rolling(window=168).mean().iloc[-1]\n",
    "            rolling_std168 = train_data[pollutant].rolling(window=168).std().iloc[-1]\n",
    "            X_test[f'{pollutant}_rolling_mean24'] = rolling_mean24\n",
    "            X_test[f'{pollutant}_rolling_std24'] = rolling_std24\n",
    "            X_test[f'{pollutant}_rolling_mean168'] = rolling_mean168\n",
    "            X_test[f'{pollutant}_rolling_std168'] = rolling_std168\n",
    "    else:\n",
    "        # Use previous predictions for lag features\n",
    "        for pollutant in target_variables:\n",
    "            # Lag 1\n",
    "            X_test[f'{pollutant}_lag1'] = test_predictions.iloc[i - 1][pollutant]\n",
    "            # Lag 24\n",
    "            if i >= 24:\n",
    "                X_test[f'{pollutant}_lag24'] = test_predictions.iloc[i - 24][pollutant]\n",
    "            else:\n",
    "                # Use last known value from training data\n",
    "                X_test[f'{pollutant}_lag24'] = train_data.iloc[-24 + i][pollutant]\n",
    "            # Lag 168\n",
    "            if i >= 168:\n",
    "                X_test[f'{pollutant}_lag168'] = test_predictions.iloc[i - 168][pollutant]\n",
    "            else:\n",
    "                # Use last known value from training data\n",
    "                X_test[f'{pollutant}_lag168'] = train_data.iloc[-168 + i][pollutant]\n",
    "            # Rolling means and stds\n",
    "            # For rolling calculations, we'll need to collect previous predictions\n",
    "            if i < 24:\n",
    "                recent_values = pd.concat([train_data[pollutant].iloc[-(24 - i):], test_predictions[pollutant].iloc[:i]])\n",
    "            else:\n",
    "                recent_values = test_predictions[pollutant].iloc[i - 24:i]\n",
    "            rolling_mean24 = recent_values.mean()\n",
    "            rolling_std24 = recent_values.std()\n",
    "            if i < 168:\n",
    "                recent_values_168 = pd.concat([train_data[pollutant].iloc[-(168 - i):], test_predictions[pollutant].iloc[:i]])\n",
    "            else:\n",
    "                recent_values_168 = test_predictions[pollutant].iloc[i - 168:i]\n",
    "            rolling_mean168 = recent_values_168.mean()\n",
    "            rolling_std168 = recent_values_168.std()\n",
    "            X_test[f'{pollutant}_rolling_mean24'] = rolling_mean24\n",
    "            X_test[f'{pollutant}_rolling_std24'] = rolling_std24\n",
    "            X_test[f'{pollutant}_rolling_mean168'] = rolling_mean168\n",
    "            X_test[f'{pollutant}_rolling_std168'] = rolling_std168\n",
    "\n",
    "    # Update interaction features\n",
    "    X_test['NO2_CO_interaction'] = X_test['valeur_NO2_lag1'] * X_test['valeur_CO_lag1']\n",
    "    X_test['PM10_PM25_interaction'] = X_test['valeur_PM10_lag1'] * X_test['valeur_PM25_lag1']\n",
    "\n",
    "    # Ensure all required features are present\n",
    "    for col in feature_columns:\n",
    "        if col not in X_test.columns:\n",
    "            X_test[col] = 0  # or appropriate default value\n",
    "\n",
    "    # Predict for each pollutant\n",
    "    for pollutant in target_variables:\n",
    "        model = models[pollutant]\n",
    "        prediction = model.predict(X_test[final_features])[0]\n",
    "        test_predictions.loc[timestamp, pollutant] = prediction\n",
    "\n",
    "    # Update test_data_pred with the new interaction features (if necessary)\n",
    "    # test_data_pred.loc[timestamp, 'NO2_CO_interaction'] = X_test['NO2_CO_interaction']\n",
    "    # test_data_pred.loc[timestamp, 'PM10_PM25_interaction'] = X_test['PM10_PM25_interaction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-03 23:00:00</th>\n",
       "      <td>20.267291</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>42.797193</td>\n",
       "      <td>8.516558</td>\n",
       "      <td>4.747267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 00:00:00</th>\n",
       "      <td>18.205523</td>\n",
       "      <td>0.217526</td>\n",
       "      <td>44.219245</td>\n",
       "      <td>8.525977</td>\n",
       "      <td>4.689853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 01:00:00</th>\n",
       "      <td>16.606518</td>\n",
       "      <td>0.226198</td>\n",
       "      <td>43.005045</td>\n",
       "      <td>8.299093</td>\n",
       "      <td>4.945912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 02:00:00</th>\n",
       "      <td>16.963767</td>\n",
       "      <td>0.218774</td>\n",
       "      <td>42.879589</td>\n",
       "      <td>8.72156</td>\n",
       "      <td>4.766376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 03:00:00</th>\n",
       "      <td>17.110345</td>\n",
       "      <td>0.210415</td>\n",
       "      <td>42.785725</td>\n",
       "      <td>8.710404</td>\n",
       "      <td>4.664991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    valeur_NO2 valeur_CO  valeur_O3 valeur_PM10 valeur_PM25\n",
       "date                                                                       \n",
       "2024-09-03 23:00:00  20.267291    0.2117  42.797193    8.516558    4.747267\n",
       "2024-09-04 00:00:00  18.205523  0.217526  44.219245    8.525977    4.689853\n",
       "2024-09-04 01:00:00  16.606518  0.226198  43.005045    8.299093    4.945912\n",
       "2024-09-04 02:00:00  16.963767  0.218774  42.879589     8.72156    4.766376\n",
       "2024-09-04 03:00:00  17.110345  0.210415  42.785725    8.710404    4.664991"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.reset_index().rename(columns={'date': 'id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-03 23:00:00</td>\n",
       "      <td>20.267291</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>42.797193</td>\n",
       "      <td>8.516558</td>\n",
       "      <td>4.747267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04 00:00:00</td>\n",
       "      <td>18.205523</td>\n",
       "      <td>0.217526</td>\n",
       "      <td>44.219245</td>\n",
       "      <td>8.525977</td>\n",
       "      <td>4.689853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04 01:00:00</td>\n",
       "      <td>16.606518</td>\n",
       "      <td>0.226198</td>\n",
       "      <td>43.005045</td>\n",
       "      <td>8.299093</td>\n",
       "      <td>4.945912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04 02:00:00</td>\n",
       "      <td>16.963767</td>\n",
       "      <td>0.218774</td>\n",
       "      <td>42.879589</td>\n",
       "      <td>8.72156</td>\n",
       "      <td>4.766376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04 03:00:00</td>\n",
       "      <td>17.110345</td>\n",
       "      <td>0.210415</td>\n",
       "      <td>42.785725</td>\n",
       "      <td>8.710404</td>\n",
       "      <td>4.664991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id valeur_NO2 valeur_CO  valeur_O3 valeur_PM10 valeur_PM25\n",
       "0 2024-09-03 23:00:00  20.267291    0.2117  42.797193    8.516558    4.747267\n",
       "1 2024-09-04 00:00:00  18.205523  0.217526  44.219245    8.525977    4.689853\n",
       "2 2024-09-04 01:00:00  16.606518  0.226198  43.005045    8.299093    4.945912\n",
       "3 2024-09-04 02:00:00  16.963767  0.218774  42.879589     8.72156    4.766376\n",
       "4 2024-09-04 03:00:00  17.110345  0.210415  42.785725    8.710404    4.664991"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions['id'] = pd.to_datetime(test_predictions['id']).dt.strftime('%Y-%m-%d %H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-03 23</td>\n",
       "      <td>20.267291</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>42.797193</td>\n",
       "      <td>8.516558</td>\n",
       "      <td>4.747267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04 00</td>\n",
       "      <td>18.205523</td>\n",
       "      <td>0.217526</td>\n",
       "      <td>44.219245</td>\n",
       "      <td>8.525977</td>\n",
       "      <td>4.689853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04 01</td>\n",
       "      <td>16.606518</td>\n",
       "      <td>0.226198</td>\n",
       "      <td>43.005045</td>\n",
       "      <td>8.299093</td>\n",
       "      <td>4.945912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04 02</td>\n",
       "      <td>16.963767</td>\n",
       "      <td>0.218774</td>\n",
       "      <td>42.879589</td>\n",
       "      <td>8.72156</td>\n",
       "      <td>4.766376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04 03</td>\n",
       "      <td>17.110345</td>\n",
       "      <td>0.210415</td>\n",
       "      <td>42.785725</td>\n",
       "      <td>8.710404</td>\n",
       "      <td>4.664991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id valeur_NO2 valeur_CO  valeur_O3 valeur_PM10 valeur_PM25\n",
       "0  2024-09-03 23  20.267291    0.2117  42.797193    8.516558    4.747267\n",
       "1  2024-09-04 00  18.205523  0.217526  44.219245    8.525977    4.689853\n",
       "2  2024-09-04 01  16.606518  0.226198  43.005045    8.299093    4.945912\n",
       "3  2024-09-04 02  16.963767  0.218774  42.879589     8.72156    4.766376\n",
       "4  2024-09-04 03  17.110345  0.210415  42.785725    8.710404    4.664991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
